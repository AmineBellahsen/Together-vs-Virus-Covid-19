{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"face_detection.ipynb","provenance":[],"authorship_tag":"ABX9TyMRL1i2Rene9tgxmdH6s9UA"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"1du8lyVKLZBz","colab_type":"code","colab":{}},"source":["pip install --upgrade google-cloud-vision"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tJIzzvGnLawl","colab_type":"code","colab":{}},"source":["import io\n","import os\n","\n","# Imports the Google Cloud client library\n","from google.cloud import vision\n","from google.cloud.vision import types\n","\n","from PIL import Image, ImageDraw\n","\n","# Instantiates a client\n","\n","#uncomment on 1st use\n","#credientials_path = \"/content/hackathon-covid-4a34b61cd5a4.json\"\n","os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = credientials_path\n","client = vision.ImageAnnotatorClient()\n","\n","# The name of the image file to annotate\n","img_file = os.path.abspath('/content/image_test.png')\n","\n","def detect_face(face_file, max_results=6):\n","        \"\"\"Uses the Vision API to detect faces in the given file.\n","\n","        Args:\n","            face_file: A file-like object containing an image with faces.\n","\n","        Returns:\n","            An array of Face objects with information about the picture.\n","        \"\"\"\n","        client = vision.ImageAnnotatorClient()\n","\n","        content = face_file.read()\n","        image = types.Image(content=content)\n","\n","        return client.face_detection(\n","            image=image, max_results=max_results).face_annotations\n","\n","def highlight_faces(image, faces, output_filename):\n","        \"\"\"Draws a polygon around the faces, then saves to output_filename.\n","\n","        Args:\n","          image: a file containing the image with the faces.\n","          faces: a list of faces found in the file. This should be in the format\n","              returned by the Vision API.\n","          output_filename: the name of the image file to be created, where the\n","              faces have polygons drawn around them.\n","        \"\"\"\n","        im = Image.open(image)\n","        draw = ImageDraw.Draw(im)\n","        # Sepecify the font-family and the font-size\n","        for face in faces:\n","            box = [(vertex.x, vertex.y)\n","                   for vertex in face.bounding_poly.vertices]\n","            draw.line(box + [box[0]], width=5, fill='#00ff00')\n","            # Place the confidence value/score of the detected faces above the\n","            # detection box in the output image\n","            draw.text(((face.bounding_poly.vertices)[0].x,\n","                       (face.bounding_poly.vertices)[0].y - 30),\n","                      str(format(face.detection_confidence, '.3f')) + '%',\n","                      fill='#FF0000')\n","        im.save(output_filename)\n","\n","with open(img_file, 'rb') as image:\n","  faces = detect_face(image)\n","  print('Found {} face{}'.format(\n","      len(faces), '' if len(faces) == 1 else 's'))\n","\n","  # Reset the file pointer, so we can read the file again\n","  image.seek(0)\n","  highlight_faces(image, faces, '/content/img_w_highlights.png')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-eh_5kwZLazg","colab_type":"code","colab":{}},"source":["import io, os\n","from numpy import random\n","from google.cloud import vision\n","import pandas as pd\n","\n","credientials_path = \"/content/hackathon-covid-4a34b61cd5a4.json\"\n","os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = credientials_path\n","client = vision.ImageAnnotatorClient()\n","\n","file_name = 'is_200327_doctor_mask_800x450.jpg'\n","image_path = os.path.join('/content', file_name)\n","\n","\n","with io.open(image_path, 'rb') as image_file:\n","    content = image_file.read()\n","\n","image = vision.types.Image(content=content)\n","response = client.object_localization(image=image)\n","localized_object_annotations = response.localized_object_annotations\n","\n","pillow_image = Image.open(image_path)\n","df = pd.DataFrame(columns=['name', 'score'])\n","for obj in localized_object_annotations:\n","    df = df.append(\n","        dict(\n","            name=obj.name,\n","            score=obj.score\n","        ),\n","        ignore_index=True)\n","    \n","    r, g, b = random.randint(150, 255), random.randint(\n","        150, 255), random.randint(150, 255)\n","\n","\n","print(df)\n","pillow_image.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AA5iTRLZLa2k","colab_type":"code","colab":{}},"source":["def localize_objects(path):\n","        \"\"\"Localize objects in the local image.\n","\n","        Args:\n","        path: The path to the local file.\n","        \"\"\"\n","        from google.cloud import vision\n","        client = vision.ImageAnnotatorClient()\n","\n","        with open(path, 'rb') as image_file:\n","            content = image_file.read()\n","        image = vision.types.Image(content=content)\n","\n","        objects = client.object_localization(\n","            image=image).localized_object_annotations\n","\n","        print('Number of objects found: {}'.format(len(objects)))\n","        for object_ in objects:\n","            print('\\n{} (confidence: {})'.format(object_.name, object_.score))\n","            print('Normalized bounding polygon vertices: ')\n","            for vertex in object_.bounding_poly.normalized_vertices:\n","                print(' - ({}, {})'.format(vertex.x, vertex.y))\n","\n","def highlight_faces(image, objects, output_filename):\n","        \"\"\"Draws a polygon around the faces, then saves to output_filename.\n","\n","        Args:\n","          image: a file containing the image with the faces.\n","          faces: a list of faces found in the file. This should be in the format\n","              returned by the Vision API.\n","          output_filename: the name of the image file to be created, where the\n","              faces have polygons drawn around them.\n","        \"\"\"\n","        im = Image.open(image)\n","        draw = ImageDraw.Draw(im)\n","        # Sepecify the font-family and the font-size\n","        for objet in objects:\n","            box = [(vertex.x, vertex.y)\n","                   for vertex in objet.bounding_poly.vertices]\n","            draw.line(box + [box[0]], width=5, fill='#00ff00')\n","            # Place the confidence value/score of the detected faces above the\n","            # detection box in the output image\n","            draw.text(((objet.bounding_poly.vertices)[0].x,\n","                       (objet.bounding_poly.vertices)[0].y - 30),\n","                      str(format(face.detection_confidence, '.3f')) + '%',\n","                      fill='#FF0000')\n","        im.save(output_filename)\n","\n","with open(img_file, 'rb') as image:\n","  objects = client.object_localization(\n","            image=image).localized_object_annotations\n","  print('Found {} face{}'.format(\n","      len(objects), '' if len(objects) == 1 else 's'))\n","\n","  # Reset the file pointer, so we can read the file again\n","  image.seek(0)\n","  highlight_faces(image, objects, '/content/img_w_highlights2.png')\n"],"execution_count":0,"outputs":[]}]}